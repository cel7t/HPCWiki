"use strict";(self.webpackChunkhpc_wiki=self.webpackChunkhpc_wiki||[]).push([[9390],{3905:function(e,t,a){a.d(t,{Zo:function(){return u},kt:function(){return m}});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var p=n.createContext({}),c=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},u=function(e){var t=c(e.components);return n.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},s=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,p=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),s=c(a),m=o,h=s["".concat(p,".").concat(m)]||s[m]||d[m]||r;return a?n.createElement(h,l(l({ref:t},u),{},{components:a})):n.createElement(h,l({ref:t},u))}));function m(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,l=new Array(r);l[0]=s;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i.mdxType="string"==typeof e?e:o,l[1]=i;for(var c=2;c<r;c++)l[c]=a[c];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}s.displayName="MDXCreateElement"},7465:function(e,t,a){a.r(t),a.d(t,{assets:function(){return u},contentTitle:function(){return p},default:function(){return m},frontMatter:function(){return i},metadata:function(){return c},toc:function(){return d}});var n=a(7462),o=a(3366),r=(a(7294),a(3905)),l=["components"],i={sidebar_position:2,sidebar_label:"CUDA",hide_table_of_contents:!0,hide_title:!0,pagination_next:null,pagination_prev:null,title:"CUDA",draft:!1},p=void 0,c={unversionedId:"faq/software/cuda",id:"faq/software/cuda",title:"CUDA",description:"CUDA",source:"@site/docs/faq/software/cuda.mdx",sourceDirName:"faq/software",slug:"/faq/software/cuda",permalink:"/docs/faq/software/cuda",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,sidebar_label:"CUDA",hide_table_of_contents:!0,hide_title:!0,pagination_next:null,pagination_prev:null,title:"CUDA",draft:!1},sidebar:"FAQ"},u={},d=[{value:"CUDA",id:"cuda",level:2},{value:"What is CUDA? Does Sharanga have GPU nodes supporting CUDA?",id:"what-is-cuda-does-sharanga-have-gpu-nodes-supporting-cuda",level:3},{value:"What are the available GPU partitions?",id:"what-are-the-available-gpu-partitions",level:3},{value:"How to compile a CUDA C, C++, or Fortran code?",id:"how-to-compile-a-cuda-c-c-or-fortran-code",level:3},{value:"How to compile a CUDA Python code?",id:"how-to-compile-a-cuda-python-code",level:3},{value:"Numba",id:"numba",level:4},{value:"PyCUDA",id:"pycuda",level:4},{value:"CuPy",id:"cupy",level:4},{value:"How to compile a CUDA Julia code?",id:"how-to-compile-a-cuda-julia-code",level:3}],s={toc:d};function m(e){var t=e.components,a=(0,o.Z)(e,l);return(0,r.kt)("wrapper",(0,n.Z)({},s,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"cuda"},"CUDA"),(0,r.kt)("h3",{id:"what-is-cuda-does-sharanga-have-gpu-nodes-supporting-cuda"},"What is CUDA? Does Sharanga have GPU nodes supporting CUDA?"),(0,r.kt)("p",null,"CUDA is a parallel computing platform developed by NVIDIA. The HPC facility has nodes that support CUDA based GPU acceleration."),(0,r.kt)("h3",{id:"what-are-the-available-gpu-partitions"},"What are the available GPU partitions?"),(0,r.kt)("p",null,"We have configured GPU (CUDA) enabled partitions with the prefix ",(0,r.kt)("inlineCode",{parentName:"p"},"gpu_"),". You can view the list of partitions by running the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"$ scontrol show partitions | grep Name=gpu_\n")),(0,r.kt)("p",null,"You may see the following output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"PartitionName=gpu_v100_1\nPartitionName=gpu_v100_2\nPartitionName=gpu_a100_8\n")),(0,r.kt)("h3",{id:"how-to-compile-a-cuda-c-c-or-fortran-code"},"How to compile a CUDA C, C++, or Fortran code?"),(0,r.kt)("p",null,"A CUDA C, C++, or Fortran code can be compiled using NVIDIA HPC Software Development Kit (SDK). The NVIDIA HPC SDK is a set of tools and libraries that enable you to develop and run applications targetting NVIDIA's CUDA architecture on HPC clusters. "),(0,r.kt)("p",null,"To compile programs using the NVIDIA HPC SDK, load the appropriate ",(0,r.kt)("inlineCode",{parentName:"p"},"nvhpc")," module. Currently, we have multiple versions of the ",(0,r.kt)("inlineCode",{parentName:"p"},"nvhpc")," module installed on Sharanga. Use the following command to view the list of available ",(0,r.kt)("inlineCode",{parentName:"p"},"nvhpc")," modules:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"$ spack find nvhpc\n")),(0,r.kt)("p",null,"Load the appropriate ",(0,r.kt)("inlineCode",{parentName:"p"},"nvhpc")," module along with its version. For example, to load the ",(0,r.kt)("inlineCode",{parentName:"p"},"nvhpc")," module for version ",(0,r.kt)("inlineCode",{parentName:"p"},"22.3"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"$ spack load nvhpc@22.3\n")),(0,r.kt)("p",null,"The NVIDIA HPC SDK is now loaded into your environment. You can now compile your CUDA C, C++, or Fortran applications using their respective compilers."),(0,r.kt)("p",null,"We have provided an equivalent GNU Compiler command for reference."),(0,r.kt)("div",{class:"content-center"},(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:"center"},"NVHPC Compiler Collection"),(0,r.kt)("th",{parentName:"tr",align:"center"},"GNU Compiler Collection"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"nvc"),(0,r.kt)("td",{parentName:"tr",align:"center"},"gcc")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"nvc++"),(0,r.kt)("td",{parentName:"tr",align:"center"},"g++")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:"center"},"nvfortran"),(0,r.kt)("td",{parentName:"tr",align:"center"},"gfortran"))))),(0,r.kt)("p",null,"For example to compile a C CUDA application ",(0,r.kt)("inlineCode",{parentName:"p"},"sample.cu")," using NVHPC C compiler ",(0,r.kt)("inlineCode",{parentName:"p"},"nvc"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"$ nvc sample.cu\n")),(0,r.kt)("h3",{id:"how-to-compile-a-cuda-python-code"},"How to compile a CUDA Python code?"),(0,r.kt)("p",null,"A CUDA Python code can be compiled using any of the following Python packages:"),(0,r.kt)("h4",{id:"numba"},"Numba"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://numba.pydata.org/"},"Numba")," is a high-performance JIT compiler for Python that supports compiling Python code to CUDA. Since there are multiple versions of Numba compiler we have not installed them globally. Instead, we recommend users to install the required version of Numba locally from Anaconda 3. The following command will install Numba in your Anaconda environment (For details on Anaconda installation, please refer to the ",(0,r.kt)("a",{parentName:"p",href:"/docs/faq/software/anaconda"},"Anaconda")," page):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"$ conda install numba cudatoolkit\n")),(0,r.kt)("p",null,"You should now be able to run your CUDA Python codes using Numba."),(0,r.kt)("h4",{id:"pycuda"},"PyCUDA"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://documen.tician.de/pycuda/"},"PyCUDA")," is a wrapper for the CUDA API. It allows you to write CUDA C++ code and directly import it in your Python code. We recommend installing PyCUDA from Anaconda 3. The following command will install PyCUDA in your Anaconda environment:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"$ conda install -c conda-forge pycuda \n")),(0,r.kt)("h4",{id:"cupy"},"CuPy"),(0,r.kt)("p",null,"If your project involves a significant usage of NumPy and SciPy, we recommend you to use ",(0,r.kt)("a",{parentName:"p",href:"https://cupy.dev/"},"CuPy"),". CuPy provides a dropdown replacement to NumPy and SciPy, which is optimized for GPU acceleration. We recommend installing CuPy from Anaconda 3. The following command will install CuPy in your Anaconda environment:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"$ conda install -c conda-forge cupy\n")),(0,r.kt)("h3",{id:"how-to-compile-a-cuda-julia-code"},"How to compile a CUDA Julia code?"),(0,r.kt)("p",null,"A CUDA Julia code can be compiled using ",(0,r.kt)("inlineCode",{parentName:"p"},"CUDA.jl"),". ",(0,r.kt)("a",{parentName:"p",href:"https://juliagpu.org/"},"CUDA.jl")," is a Julia package providing a programming interface for targeting CUDA. You can install CUDA.jl from the Julia REPL. Type ",(0,r.kt)("inlineCode",{parentName:"p"},"]")," to enter the Pkg REPL mode and run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pkg> add CUDA\n")),(0,r.kt)("p",null,"Alternatively, from the Julia REPL, you can install CUDA.jl by running the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'julia> import Pkg; Pkg.add("CUDA")\n')))}m.isMDXComponent=!0}}]);